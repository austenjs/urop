{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import yaml\r\n",
    "\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import sklearn\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from adversarial_generators.fgsm import generate_adversarial_images\r\n",
    "from model.VGG11 import VGG11\r\n",
    "from preprocess.preprocess import load_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create tf session for evaluating tensors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sess = tf.InteractiveSession()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('config/config.yml', 'r') as stream:\r\n",
    "    config = yaml.safe_load(stream)\r\n",
    "\r\n",
    "ROOT_DIRECTORY = os.path.dirname(os.path.abspath('__file__'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load weights to model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_shape = (config[\"img_height\"], config[\"img_width\"], 3)\r\n",
    "model = VGG11(input_shape = input_shape, num_classes = config[\"num_classes\"])\r\n",
    "model.load_weights(config[\"path_to_weights\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compile Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr = config[\"learning_rate\"], decay = config[\"learning_rate\"] / (config[\"epochs\"]))\r\n",
    "loss = config[\"loss_function\"]\r\n",
    "metrics = config[\"metrics\"]\r\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = [metrics])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data for adversarial training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path_to_set = os.path.join(ROOT_DIRECTORY, config[\"path_to_data\"])\r\n",
    "path_to_test_csv = os.path.join(ROOT_DIRECTORY, config[\"path_to_test_csv\"])\r\n",
    "(X_test, y_test) = load_data(path_to_test_csv, path_to_set, config[\"img_width\"], config[\"img_height\"])\r\n",
    "X_test, X_adversarial_train, y_test, y_adversarial_train = train_test_split(X_test, y_test, test_size = 0.5, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalize the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_adversarial_train = X_adversarial_train.astype(\"float32\") / 255.0\r\n",
    "X_test = X_test.astype(\"float32\") / 255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One-Hot Encode Target value"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_adversarial_train = tf.keras.utils.to_categorical(y_adversarial_train, config[\"num_classes\"])\r\n",
    "y_test = tf.keras.utils.to_categorical(y_test, config[\"num_classes\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot some adversarial images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epsilons = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]\r\n",
    "index = 6122 # Change if you want to see other images \r\n",
    "images = X_test[index:index + 64]\r\n",
    "labels = y_test[index:index + 64]\r\n",
    "f, axarr = plt.subplots(5,11, figsize = (30, 20))\r\n",
    "for i in range(5):\r\n",
    "  axarr[i, 0].imshow(images[i])\r\n",
    "  axarr[i, 0].set_xlabel(\"Original class: {}\".format(np.argmax(labels, axis = 1)[i]))\r\n",
    "for i, eps in enumerate(epsilons):\r\n",
    "  adversarial_images = generate_adversarial_images(images, labels, eps, model).eval()\r\n",
    "  new_predictions = model.predict_on_batch(adversarial_images)\r\n",
    "  new_predictions = np.argmax(new_predictions, axis = 1)\r\n",
    "  for ax in range(5):\r\n",
    "    axarr[ax, i + 1].imshow(adversarial_images[ax])\r\n",
    "    axarr[ax, i + 1].set_xlabel(\"New class: {}\".format(new_predictions[ax]))\r\n",
    "  f.axes[i + 1].set_title('Eps: {}'.format(eps))\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Duplicate model to Model A and Model B"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Model A\r\n",
    "model_a = tf.keras.models.clone_model(model)\r\n",
    "model_a.load_weights(config[\"path_to_weights\"])\r\n",
    "model_a.compile(optimizer = optimizer, loss = loss, metrics = [metrics])\r\n",
    "\r\n",
    "# Model B\r\n",
    "model_b = tf.keras.models.clone_model(model)\r\n",
    "model_b.load_weights(config[\"path_to_weights\"])\r\n",
    "model_b.compile(optimizer = optimizer, loss = loss, metrics = [metrics])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy of both models on test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Model A')\r\n",
    "model_a.evaluate(X_test, y_test)\r\n",
    "print('Model B')\r\n",
    "model_b.evaluate(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adversarial Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "eps = 0.1\r\n",
    "adversarial_images = generate_adversarial_images(X_adversarial_train, y_adversarial_train, eps, model_a).eval()\r\n",
    "new_predictions = model.predict_on_batch(adversarial_images)\r\n",
    "\r\n",
    "indexes_of_wrong_images = (np.argmax(new_predictions, axis = 1) != np.argmax(y_adversarial_train, axis = 1))\r\n",
    "\r\n",
    "# Get the images wrongly classified by model A\r\n",
    "wrong_classified_images = X_adversarial_train[indexes_of_wrong_images]\r\n",
    "\r\n",
    "# Convert list of prob to one hot encoding for traing model B\r\n",
    "new_predictions = new_predictions[indexes_of_wrong_images]\r\n",
    "new_predictions = tf.keras.utils.to_categorical(np.argmax(new_predictions, axis = 1))\r\n",
    "print(len(new_predictions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Callback for Early Stopping"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shuffle train data for adversarial training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_for_A, y_for_A = sklearn.utils.shuffle(\r\n",
    "  np.concatenate((X_adversarial_train[indexes_of_wrong_images], wrong_classified_images)),\r\n",
    "  np.concatenate((y_adversarial_train[indexes_of_wrong_images], new_predictions)),\r\n",
    "  random_state = 0)\r\n",
    "X_for_B, y_for_B = sklearn.utils.shuffle(\r\n",
    "  wrong_classified_images, y_adversarial_train[indexes_of_wrong_images],\r\n",
    "  random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model A with incorrect labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_a.fit(\r\n",
    "  x = X_for_A,\r\n",
    "  y = y_for_A,\r\n",
    "  batch_size = config[\"batch_size\"],\r\n",
    "  verbose = 1,\r\n",
    "  validation_split = 0.1,\r\n",
    "  callbacks = [callback],\r\n",
    "  epochs = config[\"epochs\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Model A')\r\n",
    "model_a.evaluate(X_test, y_test)\r\n",
    "print('Model B')\r\n",
    "model_b.evaluate(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model B with correct labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_b.fit(\r\n",
    "  x = X_for_B,\r\n",
    "  y = y_for_B,\r\n",
    "  batch_size = config[\"batch_size\"],\r\n",
    "  verbose = 1,\r\n",
    "  validation_split = 0.1,\r\n",
    "  callbacks = [callback],\r\n",
    "  epochs = config[\"epochs\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy of both models on test set after adversarial training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Model A')\r\n",
    "model_a.evaluate(X_test, y_test)\r\n",
    "print('Model B')\r\n",
    "model_b.evaluate(X_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Transferability"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# From A to B\r\n",
    "predictions = model_a.predict_on_batch(X_test)\r\n",
    "\r\n",
    "correctly_classified = (np.argmax(predictions, axis = 1) == np.argmax(y_test, axis = 1))\r\n",
    "\r\n",
    "X_correctly_classified, y_correctly_classified = X_test[correctly_classified], y_test[correctly_classified]\r\n",
    "\r\n",
    "adversarial_images = generate_adversarial_images(X_correctly_classified, y_correctly_classified, eps, model_a).eval()\r\n",
    "\r\n",
    "new_predictions = model_a.predict_on_batch(adversarial_images)\r\n",
    "indexes_of_wrong_images = (np.argmax(new_predictions, axis = 1) != np.argmax(y_correctly_classified, axis = 1))\r\n",
    "\r\n",
    "# Get the images wrongly classified by model A\r\n",
    "wrong_classified_images = X_correctly_classified[indexes_of_wrong_images]\r\n",
    "\r\n",
    "model_b.evaluate(wrong_classified_images, y_correctly_classified[indexes_of_wrong_images])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# From B to A\r\n",
    "predictions = model_b.predict_on_batch(X_test)\r\n",
    "\r\n",
    "correctly_classified = (np.argmax(predictions, axis = 1) == np.argmax(y_test, axis = 1))\r\n",
    "\r\n",
    "X_correctly_classified, y_correctly_classified = X_test[correctly_classified], y_test[correctly_classified]\r\n",
    "\r\n",
    "adversarial_images = generate_adversarial_images(X_correctly_classified, y_correctly_classified, eps, model_b).eval()\r\n",
    "\r\n",
    "new_predictions = model_b.predict_on_batch(adversarial_images)\r\n",
    "indexes_of_wrong_images = (np.argmax(new_predictions, axis = 1) != np.argmax(y_correctly_classified, axis = 1))\r\n",
    "\r\n",
    "# Get the images wrongly classified by model A\r\n",
    "wrong_classified_images = X_correctly_classified[indexes_of_wrong_images]\r\n",
    "\r\n",
    "model_a.evaluate(wrong_classified_images, y_correctly_classified[indexes_of_wrong_images])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "fe629648da5a141627e8dc366c19a389a6767e8099a5f33ddcdacbdb276296fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
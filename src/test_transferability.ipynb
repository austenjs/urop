{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import foolbox as fb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from model.VGG19 import VGG19\n",
    "from preprocess.preprocess import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/config.yml', 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "ROOT_DIRECTORY = os.path.dirname(os.path.abspath('__file__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_set = os.path.join(ROOT_DIRECTORY, config[\"path_to_data\"])\n",
    "path_to_test_csv = os.path.join(ROOT_DIRECTORY, config[\"path_to_test_csv\"])\n",
    "(X_test, y_test) = load_data(path_to_test_csv, path_to_set, config[\"img_width\"], config[\"img_height\"])\n",
    "X_test, _, y_test, _ = train_test_split(X_test, y_test, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (config[\"img_height\"], config[\"img_width\"], 3)\n",
    "name_of_models = []\n",
    "# Single Step\n",
    "path_to_single_step_attacks = os.path.join(ROOT_DIRECTORY, \"../weights2\")\n",
    "single_steps = ['DDN_alpha=1_N=1', 'FGM_alpha=1_N=1', 'FGSM_alpha=1_N=1', 'R+FGSM_alpha=1_N=1']\n",
    "for att in single_steps:\n",
    "    name_of_models.append(os.path.join(path_to_single_step_attacks, \"{}_weight_a.h5\".format(att)))\n",
    "    name_of_models.append(os.path.join(path_to_single_step_attacks, \"{}_weight_b.h5\".format(att)))\n",
    "\n",
    "# Multi Step\n",
    "path_to_multi_step_attacks = os.path.join(ROOT_DIRECTORY, \"../weights3\")\n",
    "multi_steps = ['PGD1_alpha=1_N=1', 'PGD2_alpha=1_N=1']\n",
    "for att in multi_steps:\n",
    "    name_of_models.append(os.path.join(path_to_multi_step_attacks, \"{}_weight_a.h5\".format(att)))\n",
    "    name_of_models.append(os.path.join(path_to_multi_step_attacks, \"{}_weight_b.h5\".format(att)))\n",
    "\n",
    "# Misc\n",
    "path_to_misc_attacks = os.path.join(ROOT_DIRECTORY, \"../weights4\")\n",
    "misc_attacks = ['GaussianAttack_alpha=1_N=1', 'InversionAttack_alpha=1_N=1', 'UniformAttack_alpha=1_N=1']\n",
    "for att in misc_attacks:\n",
    "    name_of_models.append(os.path.join(path_to_misc_attacks, \"{}_weight_a.h5\".format(att)))\n",
    "    name_of_models.append(os.path.join(path_to_misc_attacks, \"{}_weight_b.h5\".format(att)))\n",
    "\n",
    "name_of_models = sorted(name_of_models)\n",
    "models = []\n",
    "\n",
    "for name in name_of_models:\n",
    "    model = VGG19(input_shape = input_shape, num_classes = config[\"num_classes\"])\n",
    "    model.load_weights(name)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr = config[\"learning_rate\"], decay = config[\"learning_rate\"] / (config[\"epochs\"]))\n",
    "loss = config[\"loss_function\"]\n",
    "metrics = config[\"metrics\"]\n",
    "for model in models:\n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = [metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test transferability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = dict()\n",
    "bounds = (0, 1)\n",
    "fmodels = []\n",
    "\n",
    "for model in models:\n",
    "    fmodels.append(fb.TensorFlowModel(model, bounds=bounds, preprocessing=preprocessing))\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "# Check if models loaded properly\n",
    "for i in range(len(fmodels)):\n",
    "    name = os.path.basename(name_of_models[i])\n",
    "    print('Model {}: {}'.format(name, fb.utils.accuracy(fmodels[i], X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(fmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = fb.attacks.FGSM()\n",
    "eps = 0.031\n",
    "total_acc = 0\n",
    "metric2_score = 0\n",
    "pair_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    name = os.path.basename(name_of_models[i])\n",
    "    raw, adversarial_images, is_adv = attack(fmodels[i], X_test, y_test, epsilons = eps)\n",
    "    print('Using {} as attacker'.format(name))\n",
    "    for j in range(N):\n",
    "        if i == j:\n",
    "            continue\n",
    "        # Metric 2\n",
    "        indexes_of_wrong_images = is_adv\n",
    "        adversarial_images = adversarial_images\n",
    "        wrong_classified_images = adversarial_images[indexes_of_wrong_images]\n",
    "        metric2_score += fb.utils.accuracy(fmodels[j], wrong_classified_images, y_test[indexes_of_wrong_images])\n",
    "\n",
    "        # Metric 1\n",
    "        total_acc += fb.utils.accuracy(fmodels[j], adversarial_images, y_test)\n",
    "\n",
    "        pair_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_acc / pair_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric2_score / pair_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolbox.distances import LpDistance\n",
    "\n",
    "attack = fb.attacks.L2ClippingAwareAdditiveGaussianNoiseAttack()\n",
    "eps = 0.031\n",
    "total_acc = 0\n",
    "metric2_score = 0\n",
    "pair_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    name = os.path.basename(name_of_models[i])\n",
    "    raw, adversarial_images, is_adv = attack(fmodels[i], X_test, y_test, epsilons = eps)\n",
    "    print('Using {} as attacker'.format(name))\n",
    "    for j in range(N):\n",
    "        if i == j:\n",
    "            continue\n",
    "        # Metric 2\n",
    "        indexes_of_wrong_images = is_adv\n",
    "        adversarial_images = adversarial_images\n",
    "        wrong_classified_images = adversarial_images[indexes_of_wrong_images]\n",
    "        metric2_score += fb.utils.accuracy(fmodels[j], wrong_classified_images, y_test[indexes_of_wrong_images])\n",
    "\n",
    "        # Metric 1\n",
    "        total_acc += fb.utils.accuracy(fmodels[j], adversarial_images, y_test)\n",
    "\n",
    "        pair_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_acc / pair_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric2_score / pair_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = fb.attacks.FGM()\n",
    "eps = 1\n",
    "total_acc = 0\n",
    "metric2_score = 0\n",
    "pair_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    name = os.path.basename(name_of_models[i])\n",
    "    raw, adversarial_images, is_adv = attack(fmodels[i], X_test, y_test, epsilons = eps)\n",
    "    print('Using {} as attacker'.format(name))\n",
    "    for j in range(N):\n",
    "        if i == j:\n",
    "            continue\n",
    "        # Metric 1\n",
    "        total_acc += fb.utils.accuracy(fmodels[j], adversarial_images, y_test)\n",
    "\n",
    "        # Metric 2\n",
    "        indexes_of_wrong_images = is_adv\n",
    "        adversarial_images = adversarial_images\n",
    "        wrong_classified_images = adversarial_images[indexes_of_wrong_images]\n",
    "        metric2_score += fb.utils.accuracy(fmodels[j], wrong_classified_images, y_test[indexes_of_wrong_images])\n",
    "\n",
    "        pair_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_acc / pair_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric2_score / pair_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56cc440d07d7621ce49a7c460588d364d8586766d6362c42fe0a56848fc50829"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('urop')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

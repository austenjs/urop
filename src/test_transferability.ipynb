{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import foolbox as fb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from adversarial_generators.fgsm import generate_adversarial_images\n",
    "from model.VGG19 import VGG19\n",
    "from preprocess.preprocess import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/config.yml', 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "ROOT_DIRECTORY = os.path.dirname(os.path.abspath('__file__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (config[\"img_height\"], config[\"img_width\"], 3)\n",
    "model_a = VGG19(input_shape = input_shape, num_classes = config[\"num_classes\"])\n",
    "model_b = VGG19(input_shape = input_shape, num_classes = config[\"num_classes\"])\n",
    "\n",
    "eps = 0.05\n",
    "path_to_weight_a = \"../weights/{}_weight_a.h5\".format(eps)\n",
    "path_to_weight_b = \"../weights/{}_weight_b.h5\".format(eps)\n",
    "model_a.load_weights(path_to_weight_a)\n",
    "model_b.load_weights(path_to_weight_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: 0\n",
      "loaded: 500\n",
      "loaded: 1000\n",
      "loaded: 1500\n",
      "loaded: 2000\n",
      "loaded: 2500\n",
      "loaded: 3000\n",
      "loaded: 3500\n",
      "loaded: 4000\n",
      "loaded: 4500\n",
      "loaded: 5000\n",
      "loaded: 5500\n",
      "loaded: 6000\n",
      "loaded: 6500\n",
      "loaded: 7000\n",
      "loaded: 7500\n",
      "loaded: 8000\n",
      "loaded: 8500\n",
      "loaded: 9000\n",
      "loaded: 9500\n",
      "loaded: 10000\n",
      "loaded: 10500\n",
      "loaded: 11000\n",
      "loaded: 11500\n",
      "loaded: 12000\n",
      "loaded: 12500\n"
     ]
    }
   ],
   "source": [
    "path_to_set = os.path.join(ROOT_DIRECTORY, config[\"path_to_data\"])\n",
    "path_to_test_csv = os.path.join(ROOT_DIRECTORY, config[\"path_to_test_csv\"])\n",
    "(X_test, y_test) = load_data(path_to_test_csv, path_to_set, config[\"img_width\"], config[\"img_height\"])\n",
    "X_test, _, y_test, _ = train_test_split(X_test, y_test, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\auste\\anaconda3\\envs\\urop\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr = config[\"learning_rate\"], decay = config[\"learning_rate\"] / (config[\"epochs\"]))\n",
    "loss = config[\"loss_function\"]\n",
    "metrics = config[\"metrics\"]\n",
    "model_a.compile(optimizer = optimizer, loss = loss, metrics = [metrics])\n",
    "model_b.compile(optimizer = optimizer, loss = loss, metrics = [metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encode Target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.keras.utils.to_categorical(y_test, config[\"num_classes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate accuracy of both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A\n",
      "198/198 [==============================] - 21s 103ms/step - loss: 1.8161 - accuracy: 0.6293\n",
      "Model B\n",
      "198/198 [==============================] - 21s 103ms/step - loss: 0.0475 - accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.047482799738645554, 0.9906571507453918]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model A')\n",
    "model_a.evaluate(X_test, y_test)\n",
    "print('Model B')\n",
    "model_b.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 11s 100ms/step - loss: 2.6356 - accuracy: 0.5927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6356091499328613, 0.5927171111106873]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From A to B\n",
    "predictions = model_a.predict_on_batch(X_test)\n",
    "\n",
    "correctly_classified = (np.argmax(predictions, axis = 1) == np.argmax(y_test, axis = 1))\n",
    "\n",
    "X_correctly_classified, y_correctly_classified = X_test[correctly_classified], y_test[correctly_classified]\n",
    "\n",
    "adversarial_images = generate_adversarial_images(X_correctly_classified, y_correctly_classified, eps, model_a).numpy()\n",
    "\n",
    "new_predictions = model_a.predict_on_batch(adversarial_images)\n",
    "indexes_of_wrong_images = (np.argmax(new_predictions, axis = 1) != np.argmax(y_correctly_classified, axis = 1))\n",
    "\n",
    "# Get the images wrongly classified by model A\n",
    "wrong_classified_images = adversarial_images[indexes_of_wrong_images]\n",
    "\n",
    "model_b.evaluate(wrong_classified_images, y_correctly_classified[indexes_of_wrong_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 13s 107ms/step - loss: 5.0505 - accuracy: 0.1371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.050490379333496, 0.1371428519487381]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From B to A\n",
    "predictions = model_b.predict_on_batch(X_test)\n",
    "\n",
    "correctly_classified = (np.argmax(predictions, axis = 1) == np.argmax(y_test, axis = 1))\n",
    "\n",
    "X_correctly_classified, y_correctly_classified = X_test[correctly_classified], y_test[correctly_classified]\n",
    "\n",
    "adversarial_images = generate_adversarial_images(X_correctly_classified, y_correctly_classified, eps, model_b).numpy()\n",
    "\n",
    "new_predictions = model_b.predict_on_batch(adversarial_images)\n",
    "indexes_of_wrong_images = (np.argmax(new_predictions, axis = 1) != np.argmax(y_correctly_classified, axis = 1))\n",
    "\n",
    "# Get the images wrongly classified by model A\n",
    "wrong_classified_images = adversarial_images[indexes_of_wrong_images]\n",
    "\n",
    "model_a.evaluate(wrong_classified_images, y_correctly_classified[indexes_of_wrong_images])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: 0\n",
      "loaded: 500\n",
      "loaded: 1000\n",
      "loaded: 1500\n",
      "loaded: 2000\n",
      "loaded: 2500\n",
      "loaded: 3000\n",
      "loaded: 3500\n",
      "loaded: 4000\n",
      "loaded: 4500\n",
      "loaded: 5000\n",
      "loaded: 5500\n",
      "loaded: 6000\n",
      "loaded: 6500\n",
      "loaded: 7000\n",
      "loaded: 7500\n",
      "loaded: 8000\n",
      "loaded: 8500\n",
      "loaded: 9000\n",
      "loaded: 9500\n",
      "loaded: 10000\n",
      "loaded: 10500\n",
      "loaded: 11000\n",
      "loaded: 11500\n",
      "loaded: 12000\n",
      "loaded: 12500\n"
     ]
    }
   ],
   "source": [
    "(X_test, y_test) = load_data(path_to_test_csv, path_to_set, config[\"img_width\"], config[\"img_height\"])\n",
    "X_test, _, y_test, _ = train_test_split(X_test, y_test, test_size = 0.5, random_state = 0) # Get the initial label instead of one-hot encoded version\n",
    "X_test = X_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\auste\\anaconda3\\envs\\urop\\lib\\site-packages\\foolbox\\models\\tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "0.6292953491210938\n",
      "0.9906571507453918\n"
     ]
    }
   ],
   "source": [
    "preprocessing = dict()\n",
    "bounds = (0, 1)\n",
    "fmodel_a = fb.TensorFlowModel(model_a, bounds=bounds, preprocessing=preprocessing)\n",
    "fmodel_b = fb.TensorFlowModel(model_b, bounds=bounds, preprocessing=preprocessing)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "\n",
    "# Check if model loaded properly\n",
    "print(fb.utils.accuracy(fmodel_a, X_test, y_test))\n",
    "print(fb.utils.accuracy(fmodel_b, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projected Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps = 6, steps = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861111044883728"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From A to B\n",
    "predictions = model_a.predict_on_batch(X_test)\n",
    "\n",
    "correctly_classified = (np.argmax(predictions, axis = 1) == y_test)\n",
    "\n",
    "X_correctly_classified, y_correctly_classified = X_test[correctly_classified], y_test[correctly_classified]\n",
    "raw, adversarial_images, is_adv = attack(fmodel_a, X_correctly_classified, y_correctly_classified, epsilons = eps)\n",
    "\n",
    "# Get the images wrongly classified by model A\n",
    "indexes_of_wrong_images = is_adv.numpy()\n",
    "adversarial_images = adversarial_images.numpy()\n",
    "wrong_classified_images = adversarial_images[indexes_of_wrong_images]\n",
    "\n",
    "fb.utils.accuracy(fmodel_b, wrong_classified_images, y_correctly_classified[indexes_of_wrong_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23880596458911896"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From B to A\n",
    "predictions = model_b.predict_on_batch(X_test)\n",
    "\n",
    "correctly_classified = (np.argmax(predictions, axis = 1) == y_test)\n",
    "\n",
    "X_correctly_classified, y_correctly_classified = X_test[correctly_classified], y_test[correctly_classified]\n",
    "raw, adversarial_images, is_adv = attack(fmodel_b, X_correctly_classified, y_correctly_classified, epsilons = eps)\n",
    "\n",
    "# Get the images wrongly classified by model B\n",
    "indexes_of_wrong_images = is_adv.numpy()\n",
    "adversarial_images = adversarial_images.numpy()\n",
    "wrong_classified_images = adversarial_images[indexes_of_wrong_images]\n",
    "\n",
    "fb.utils.accuracy(fmodel_a, wrong_classified_images, y_correctly_classified[indexes_of_wrong_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56cc440d07d7621ce49a7c460588d364d8586766d6362c42fe0a56848fc50829"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('urop': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
